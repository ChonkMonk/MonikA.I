{
    "model_name": "PygmalionAI/pygmalion-2.7b", #Model used: 350m/1.3b/2.7b/6b
    "max_new_tokens": 150, #number of tokens generated at each answer (200 is good, reduce if not enough memory)
    "temperature": 0.6, #between 0.6 and 1 (more = answer more random, less = less diverse but follows more persona)
    "repetition_penalty": 1.15, #penalize repeted answers (1-1.2)
    "top_p": 0.9,
    "top_k": 0,
    "do_sample": true,
    "typical_p":1.0,
    "char_json": "monika.json", #character json to load, highly customizable
    "context_size": 6 #number of sentences taken from the history to reme√πber the conext (+ = more context but + computing)
}